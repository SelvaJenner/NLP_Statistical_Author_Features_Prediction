{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "418f8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "#preprocessing\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "#model building\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#model evaluation\n",
    "from sklearn.metrics import accuracy_score, f1_score, average_precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c50433e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681279</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  I could write some really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681280</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  'I have the second yeast i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681281</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  Your 'boyfriend' is fuckin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681282</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan:    Just to clarify, I am as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681283</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Hey everybody...and Susan,  You might a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id gender  age              topic      sign          date  \\\n",
       "0       2059027   male   15            Student       Leo   14,May,2004   \n",
       "1       2059027   male   15            Student       Leo   13,May,2004   \n",
       "2       2059027   male   15            Student       Leo   12,May,2004   \n",
       "3       2059027   male   15            Student       Leo   12,May,2004   \n",
       "4       3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "...         ...    ...  ...                ...       ...           ...   \n",
       "681279  1713845   male   23            Student    Taurus  01,July,2004   \n",
       "681280  1713845   male   23            Student    Taurus  01,July,2004   \n",
       "681281  1713845   male   23            Student    Taurus  01,July,2004   \n",
       "681282  1713845   male   23            Student    Taurus  01,July,2004   \n",
       "681283  1713845   male   23            Student    Taurus  01,July,2004   \n",
       "\n",
       "                                                     text  \n",
       "0                  Info has been found (+/- 100 pages,...  \n",
       "1                  These are the team members:   Drewe...  \n",
       "2                  In het kader van kernfusie op aarde...  \n",
       "3                        testing!!!  testing!!!            \n",
       "4                    Thanks to Yahoo!'s Toolbar I can ...  \n",
       "...                                                   ...  \n",
       "681279         Dear Susan,  I could write some really ...  \n",
       "681280         Dear Susan,  'I have the second yeast i...  \n",
       "681281         Dear Susan,  Your 'boyfriend' is fuckin...  \n",
       "681282         Dear Susan:    Just to clarify, I am as...  \n",
       "681283         Hey everybody...and Susan,  You might a...  \n",
       "\n",
       "[681284 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv('blogtext.csv')\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "316dcb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_data.sample(n = 1000)\n",
    "df.reset_index(drop='first',inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e378f988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1334509</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>::: CHEER UP BITCH :::     I needed a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>870139</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>Non-Profit</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>27,April,2003</td>\n",
       "      <td>a what???   Yes...a door-handle-less ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3369833</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Tourism</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>05,July,2004</td>\n",
       "      <td>Monday :  relaxed and fun start ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1593902</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>15,August,2003</td>\n",
       "      <td>If you said that you could kill the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1859920</td>\n",
       "      <td>male</td>\n",
       "      <td>26</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>18,September,2003</td>\n",
       "      <td>Oh my god where to start, well its ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>3654939</td>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>12,July,2004</td>\n",
       "      <td>Jeff and John's NFL weekly Picks  Your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2664554</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Libra</td>\n",
       "      <td>12,January,2004</td>\n",
       "      <td>Just saw a news flash on the internet t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2534568</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Education</td>\n",
       "      <td>Leo</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>Wow! I just spent about two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1414354</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Non-Profit</td>\n",
       "      <td>Leo</td>\n",
       "      <td>01,June,2004</td>\n",
       "      <td>I know that everyone has heard at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1093457</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>20,June,2003</td>\n",
       "      <td>Well, i now own my Harry potter and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  gender  age       topic         sign               date  \\\n",
       "0    1334509  female   23  Accounting       Taurus     05,August,2004   \n",
       "1     870139  female   24  Non-Profit       Gemini      27,April,2003   \n",
       "2    3369833    male   23     Tourism  Sagittarius       05,July,2004   \n",
       "3    1593902    male   15     Student       Taurus     15,August,2003   \n",
       "4    1859920    male   26      indUnk       Cancer  18,September,2003   \n",
       "..       ...     ...  ...         ...          ...                ...   \n",
       "995  3654939    male   27      indUnk       Cancer       12,July,2004   \n",
       "996  2664554    male   35      indUnk        Libra    12,January,2004   \n",
       "997  2534568    male   17   Education          Leo       10,June,2004   \n",
       "998  1414354    male   24  Non-Profit          Leo       01,June,2004   \n",
       "999  1093457    male   16  Technology        Virgo       20,June,2003   \n",
       "\n",
       "                                                  text  \n",
       "0            ::: CHEER UP BITCH :::     I needed a ...  \n",
       "1             a what???   Yes...a door-handle-less ...  \n",
       "2                  Monday :  relaxed and fun start ...  \n",
       "3               If you said that you could kill the...  \n",
       "4               Oh my god where to start, well its ...  \n",
       "..                                                 ...  \n",
       "995         Jeff and John's NFL weekly Picks  Your ...  \n",
       "996         Just saw a news flash on the internet t...  \n",
       "997                    Wow! I just spent about two ...  \n",
       "998               I know that everyone has heard at...  \n",
       "999             Well, i now own my Harry potter and...  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb6ea4c2",
   "metadata": {},
   "source": [
    "Preprocessing steps\n",
    "a. Remove unwanted characters\n",
    "b. Convert text to lowercase\n",
    "c. Remove unwanted spaces\n",
    "d. Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c6d6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              ::: CHEER UP BITCH :::     I needed a ...\n",
       "1               a what???   Yes...a door-handle-less ...\n",
       "2                    Monday :  relaxed and fun start ...\n",
       "3                 If you said that you could kill the...\n",
       "4                 Oh my god where to start, well its ...\n",
       "                             ...                        \n",
       "995           Jeff and John's NFL weekly Picks  Your ...\n",
       "996           Just saw a news flash on the internet t...\n",
       "997                      Wow! I just spent about two ...\n",
       "998                 I know that everyone has heard at...\n",
       "999               Well, i now own my Harry potter and...\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "564bc2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "\n",
    "    # Remove unwanted characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove unwanted spaces\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = [lemmatizer.lemmatize(word) for word in filtered_text]\n",
    "\n",
    "    # Join the processed words back into a single string\n",
    "    processed_text = \" \".join(lemmatized_text)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a243fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e62a2e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      cheer bitch needed good laugh damit got one bi...\n",
       "1      yesa doorhandleless toyota camrythats said dri...\n",
       "2      monday relaxed fun start race wed agreed pyro ...\n",
       "3      said could kill thing inside youre liar everyt...\n",
       "4      oh god start well since posted reason hey much...\n",
       "                             ...                        \n",
       "995    jeff john nfl weekly pick favorite college foo...\n",
       "996    saw news flash internet kartik iyer heading in...\n",
       "997    wow spent two hour putting together post james...\n",
       "998    know everyone heard one point another fiasco u...\n",
       "999    well harry potter order phenix book yipee hair...\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text"
   ]
  },
  {
   "cell_type": "raw",
   "id": "adba5aa5",
   "metadata": {},
   "source": [
    "Label columns to merge: “gender”, “age”, “topic”, “sign”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a264a450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [female, 23, Accounting, Taurus]\n",
       "1      [female, 24, Non-Profit, Gemini]\n",
       "2      [male, 23, Tourism, Sagittarius]\n",
       "3           [male, 15, Student, Taurus]\n",
       "4            [male, 26, indUnk, Cancer]\n",
       "                     ...               \n",
       "995          [male, 27, indUnk, Cancer]\n",
       "996           [male, 35, indUnk, Libra]\n",
       "997          [male, 17, Education, Leo]\n",
       "998         [male, 24, Non-Profit, Leo]\n",
       "999       [male, 16, Technology, Virgo]\n",
       "Name: labels, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the columns into a single column\n",
    "df['labels'] = df.apply(lambda row: [row['gender'], str(row['age']), row['topic'], row['sign']], axis=1)\n",
    "df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6b02dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['id','gender','age','topic','sign','date'],inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63c061d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'labels'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af36b769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cheer bitch needed good laugh damit got one bi...</td>\n",
       "      <td>[female, 23, Accounting, Taurus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yesa doorhandleless toyota camrythats said dri...</td>\n",
       "      <td>[female, 24, Non-Profit, Gemini]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>monday relaxed fun start race wed agreed pyro ...</td>\n",
       "      <td>[male, 23, Tourism, Sagittarius]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>said could kill thing inside youre liar everyt...</td>\n",
       "      <td>[male, 15, Student, Taurus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh god start well since posted reason hey much...</td>\n",
       "      <td>[male, 26, indUnk, Cancer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>jeff john nfl weekly pick favorite college foo...</td>\n",
       "      <td>[male, 27, indUnk, Cancer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>saw news flash internet kartik iyer heading in...</td>\n",
       "      <td>[male, 35, indUnk, Libra]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>wow spent two hour putting together post james...</td>\n",
       "      <td>[male, 17, Education, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>know everyone heard one point another fiasco u...</td>\n",
       "      <td>[male, 24, Non-Profit, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>well harry potter order phenix book yipee hair...</td>\n",
       "      <td>[male, 16, Technology, Virgo]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    cheer bitch needed good laugh damit got one bi...   \n",
       "1    yesa doorhandleless toyota camrythats said dri...   \n",
       "2    monday relaxed fun start race wed agreed pyro ...   \n",
       "3    said could kill thing inside youre liar everyt...   \n",
       "4    oh god start well since posted reason hey much...   \n",
       "..                                                 ...   \n",
       "995  jeff john nfl weekly pick favorite college foo...   \n",
       "996  saw news flash internet kartik iyer heading in...   \n",
       "997  wow spent two hour putting together post james...   \n",
       "998  know everyone heard one point another fiasco u...   \n",
       "999  well harry potter order phenix book yipee hair...   \n",
       "\n",
       "                               labels  \n",
       "0    [female, 23, Accounting, Taurus]  \n",
       "1    [female, 24, Non-Profit, Gemini]  \n",
       "2    [male, 23, Tourism, Sagittarius]  \n",
       "3         [male, 15, Student, Taurus]  \n",
       "4          [male, 26, indUnk, Cancer]  \n",
       "..                                ...  \n",
       "995        [male, 27, indUnk, Cancer]  \n",
       "996         [male, 35, indUnk, Libra]  \n",
       "997        [male, 17, Education, Leo]  \n",
       "998       [male, 24, Non-Profit, Leo]  \n",
       "999     [male, 16, Technology, Virgo]  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3febfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = df['text']  # Features\n",
    "y = df['labels']  # Labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0849db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term-Document Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Assuming you have the training and testing features as X_train and X_test\n",
    "\n",
    "# Create the count vectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "# Fit and transform the training features\n",
    "X_train_cvectorized = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing features\n",
    "X_test_cvectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Print the term-document matrix\n",
    "print(\"Term-Document Matrix:\")\n",
    "print(X_train_cvectorized.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f148668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'female': 498,\n",
       " '23': 109,\n",
       " 'Accounting': 10,\n",
       " 'Taurus': 99,\n",
       " '24': 116,\n",
       " 'Non-Profit': 21,\n",
       " 'Gemini': 87,\n",
       " 'male': 502,\n",
       " 'Tourism': 7,\n",
       " 'Sagittarius': 72,\n",
       " '15': 63,\n",
       " 'Student': 223,\n",
       " '26': 90,\n",
       " 'indUnk': 362,\n",
       " 'Cancer': 91,\n",
       " '27': 66,\n",
       " 'Technology': 67,\n",
       " '33': 26,\n",
       " 'Scorpio': 81,\n",
       " '44': 3,\n",
       " 'Aquarius': 76,\n",
       " '43': 11,\n",
       " '14': 45,\n",
       " 'Virgo': 88,\n",
       " '16': 104,\n",
       " '25': 91,\n",
       " 'Leo': 80,\n",
       " '17': 101,\n",
       " 'Pisces': 72,\n",
       " '39': 10,\n",
       " '35': 34,\n",
       " 'Aries': 112,\n",
       " 'Capricorn': 65,\n",
       " 'Libra': 77,\n",
       " '42': 4,\n",
       " 'Engineering': 19,\n",
       " 'Arts': 53,\n",
       " 'Government': 10,\n",
       " 'Internet': 26,\n",
       " '34': 29,\n",
       " 'Publishing': 11,\n",
       " '37': 10,\n",
       " 'Communications-Media': 33,\n",
       " 'Science': 11,\n",
       " 'Education': 54,\n",
       " 'Sports-Recreation': 5,\n",
       " '41': 6,\n",
       " 'Religion': 7,\n",
       " '36': 17,\n",
       " 'HumanResources': 2,\n",
       " '38': 13,\n",
       " 'Law': 12,\n",
       " 'Telecommunications': 7,\n",
       " '13': 17,\n",
       " 'Fashion': 4,\n",
       " '47': 8,\n",
       " 'BusinessServices': 5,\n",
       " '40': 11,\n",
       " 'Manufacturing': 4,\n",
       " 'RealEstate': 6,\n",
       " 'Advertising': 8,\n",
       " 'Banking': 5,\n",
       " 'Museums-Libraries': 2,\n",
       " 'InvestmentBanking': 1,\n",
       " 'Architecture': 2,\n",
       " 'Military': 4,\n",
       " '46': 4,\n",
       " 'Biotech': 1,\n",
       " 'Automotive': 2,\n",
       " 'Marketing': 3,\n",
       " '48': 4,\n",
       " '45': 8,\n",
       " 'Transportation': 1,\n",
       " 'Chemicals': 4,\n",
       " 'Maritime': 1,\n",
       " 'Consulting': 3,\n",
       " 'Environment': 1,\n",
       " 'LawEnforcement-Security': 1,\n",
       " 'Construction': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = dict()\n",
    "\n",
    "for Labels in df.labels.values:\n",
    "    for label in Labels:\n",
    "        if label in label_counts:\n",
    "            label_counts[label] += 1\n",
    "        else:\n",
    "            label_counts[label] = 1\n",
    "            \n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b0616d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert your train and test labels using MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(classes=list(label_counts.keys()))\n",
    "train_labels_binary = mlb.fit_transform(y_train)\n",
    "test_labels_binary = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f97f9b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', '23', 'Accounting', 'Taurus', '24', 'Non-Profit',\n",
       "       'Gemini', 'male', 'Tourism', 'Sagittarius', '15', 'Student', '26',\n",
       "       'indUnk', 'Cancer', '27', 'Technology', '33', 'Scorpio', '44',\n",
       "       'Aquarius', '43', '14', 'Virgo', '16', '25', 'Leo', '17', 'Pisces',\n",
       "       '39', '35', 'Aries', 'Capricorn', 'Libra', '42', 'Engineering',\n",
       "       'Arts', 'Government', 'Internet', '34', 'Publishing', '37',\n",
       "       'Communications-Media', 'Science', 'Education',\n",
       "       'Sports-Recreation', '41', 'Religion', '36', 'HumanResources',\n",
       "       '38', 'Law', 'Telecommunications', '13', 'Fashion', '47',\n",
       "       'BusinessServices', '40', 'Manufacturing', 'RealEstate',\n",
       "       'Advertising', 'Banking', 'Museums-Libraries', 'InvestmentBanking',\n",
       "       'Architecture', 'Military', '46', 'Biotech', 'Automotive',\n",
       "       'Marketing', '48', '45', 'Transportation', 'Chemicals', 'Maritime',\n",
       "       'Consulting', 'Environment', 'LawEnforcement-Security',\n",
       "       'Construction'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22ce45cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression())"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a LogisticRegression classifier\n",
    "base_classifier = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "# Wrap the base classifier in OneVsRestClassifier\n",
    "classifier = OneVsRestClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier on your training data\n",
    "classifier.fit(X_train_cvectorized, train_labels_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00319732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.0\n",
      "F1 Score: 0.2409867172675522\n",
      "Average Precision Score: 0.12196993670886076\n",
      "Average Recall Score: 0.15875\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = classifier.predict(X_test_cvectorized)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(test_labels_binary, predictions)\n",
    "f1 = f1_score(test_labels_binary, predictions, average='micro')\n",
    "avg_precision = average_precision_score(test_labels_binary, predictions, average='micro')\n",
    "avg_recall = recall_score(test_labels_binary, predictions, average='micro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Average Precision Score:\", avg_precision)\n",
    "print(\"Average Recall Score:\", avg_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d5aff03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.0\n",
      "F1 Score (micro): 0.2409867172675522\n",
      "F1 Score (macro): 0.019047729248370622\n",
      "F1 Score (weighted): 0.16728699099503988\n",
      "Average Precision Score (micro): 0.12196993670886076\n",
      "Average Precision Score (macro): nan\n",
      "Average Precision Score (weighted): 0.22188965693947527\n",
      "Average Recall Score (micro): 0.15875\n",
      "Average Recall Score (macro): 0.017533681860948114\n",
      "Average Recall Score (weighted): 0.15875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, average_precision_score, recall_score\n",
    "\n",
    "# Fit the classifier on your training data\n",
    "classifier.fit(X_train_cvectorized, train_labels_binary)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = classifier.predict(X_test_cvectorized)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(test_labels_binary, predictions)\n",
    "f1_micro = f1_score(test_labels_binary, predictions, average='micro')\n",
    "f1_macro = f1_score(test_labels_binary, predictions, average='macro')\n",
    "f1_weighted = f1_score(test_labels_binary, predictions, average='weighted')\n",
    "avg_precision_micro = average_precision_score(test_labels_binary, predictions, average='micro')\n",
    "avg_precision_macro = average_precision_score(test_labels_binary, predictions, average='macro')\n",
    "avg_precision_weighted = average_precision_score(test_labels_binary, predictions, average='weighted')\n",
    "avg_recall_micro = recall_score(test_labels_binary, predictions, average='micro')\n",
    "avg_recall_macro = recall_score(test_labels_binary, predictions, average='macro')\n",
    "avg_recall_weighted = recall_score(test_labels_binary, predictions, average='weighted')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "print(\"F1 Score (micro):\", f1_micro)\n",
    "print(\"F1 Score (macro):\", f1_macro)\n",
    "print(\"F1 Score (weighted):\", f1_weighted)\n",
    "print(\"Average Precision Score (micro):\", avg_precision_micro)\n",
    "print(\"Average Precision Score (macro):\", avg_precision_macro)\n",
    "print(\"Average Precision Score (weighted):\", avg_precision_weighted)\n",
    "print(\"Average Recall Score (micro):\", avg_recall_micro)\n",
    "print(\"Average Recall Score (macro):\", avg_recall_macro)\n",
    "print(\"Average Recall Score (weighted):\", avg_recall_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86b7f746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: 156\n",
      "Title: relfection 5 day practicum saturday morning feeling thursday afternoon become reality got cold flu week interesting really need think implication observation set plan following week observation week gone havent much except thought show mean better get good mileage thought time planned productive following week despite experience limited experience think supervising teacher teaching lot desired example poor classroom management abound two example cite order oneonone math reading testing repeatedly given class loose instruction play thing work within 5 minute naturally class thing shouldnt yell top voice dare heart sore lecture learn give poor instruction mistake kid get diverted think make sense useful activity available prepared would best way go planning day lesson obvious 1on1 work need something engage student getting play productive get kid excited another case oneonone testing asked child tested number come 7 quickly student playing something else come running say 8 child tested speak dare go sit rubbish bin child go sits rubbish bin teacher hasnt specified child come back forgets testing walked asked whether knew punished didnt explained asked ready behave nodded head let join classmate someone doesnt know reason punished doesnt stand reason learn anything probably either resent teacher reduced selfimage impressed habit drilled bear mind need assessment need sense control otherwise observed people university pretty demonstration read book story gingerbread man time experimented instructional technique reason think small lowrisk environment held class attention controlled le controllable student start need build challenging instructional task compared last school went practicum school put little thought accommodate student learner last school student teacher guided tour school powhiri welcome proactive mentor arranged time meet u requirement get paid university mentor avondale didnt seem know meet even though presumeably get paid set time friday afternoon found busy staff socialising event cancelled talented student really talented behind student behind several esol child one russia also developmental problem find esol student observation two young polynesian recent immigrant challenge preconception mine polynesian school would born hence good english sure well monday may sicky day recovered sufficiently thats thought lie beneath surface memory maybe append later\n",
      "True Label: ('female', '15', 'Student', 'Aquarius')\n",
      "Predicted Label: ('male',)\n",
      "\n",
      "Example: 97\n",
      "Title: god miss ex much broke month ago broke say lot mind doesnt know direction life taking doesnt want hold back hold back he want really mean doesnt want hold back say he even sure want settle good doesnt know im last girl want date oh okay im sitting missing wierd thing first didnt even seem like broken still thing ive moved together time anymore reality setting together love much shake head sigh hope best\n",
      "True Label: ('male', 'indUnk', 'Cancer', '16')\n",
      "Predicted Label: ('female',)\n",
      "\n",
      "Example: 94\n",
      "Title: spock would democrat trekkie seen episode movie phrase need many outweigh need stuck liberal mind republican believe individual responsibility society like always people myriad reason support without considerable help requires taxing billionaire citizen country think percentage point spock would say right thing u exorbitantly wealthy political article week apologize\n",
      "True Label: ('male', 'Sagittarius', 'Student', '17')\n",
      "Predicted Label: ('male',)\n",
      "\n",
      "Example: 39\n",
      "Title: forrest gump urllink movie belong inmany different outcome brought urllink quizilla\n",
      "True Label: ('female', '26', 'Cancer', 'Publishing')\n",
      "Predicted Label: ('female',)\n",
      "\n",
      "Example: 14\n",
      "Title: tonight fun went saw 50 first date cape kaci emily claire b karen tera funny movie definitely oscar worthy haha fun time though tomorrow going shopping caroline american eagle gift card use im excited hehe much say im happy actually went something great hehe\n",
      "True Label: ('female', '15', 'Student', 'Aries')\n",
      "Predicted Label: ('female',)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the predicted labels back to their original format\n",
    "predicted_labels = mlb.inverse_transform(predictions)\n",
    "true_labels = mlb.inverse_transform(test_labels_binary)\n",
    "\n",
    "# Select five random indices\n",
    "random_indices = np.random.choice(len(true_labels), size=5, replace=False)\n",
    "\n",
    "# Print the true and predicted labels for the selected examples\n",
    "for i in random_indices:\n",
    "    print(\"Example:\",i+1)\n",
    "    print(\"Title:\", X_test.iloc[i+1])\n",
    "    print(\"True Label:\", true_labels[i])\n",
    "    print(\"Predicted Label:\", predicted_labels[i])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e965e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea024f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
